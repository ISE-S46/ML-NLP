{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Lambda Function"
      ],
      "metadata": {
        "id": "IYj4YpMQtQUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lambda function for addition\n",
        "add = lambda x, y: x + y\n",
        "# Using the lambda function\n",
        "result = add(3, 5)\n",
        "print(result)  # Output: 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o16jOWGHxH1P",
        "outputId": "17a079ff-6e3a-4358-b031-ba3d96befd25"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quadratic Formula using lambda function"
      ],
      "metadata": {
        "id": "3DjKVZ6btZuy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ak3dEqAFPQB0",
        "outputId": "59444e90-0440-4980-e2e3-26ec760e994a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The roots are: (2.0, 1.0)\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "quadratic_roots = lambda a, b, c: (\n",
        "    (-b + math.sqrt(b**2-(4*a*c)))/2*a,\n",
        "    (-b - math.sqrt(b**2-(4*a*c)))/2*a\n",
        ")\n",
        "a, b, c = 1, -3, 2\n",
        "roots = quadratic_roots(a, b, c)\n",
        "print(f\"The roots are: {roots}\") # Output as a Tuple"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RDDs (Resilient Distributed Datasets)\n",
        "\n",
        "immutable, partitioned collection of elements that can be operated on in parallel.\n",
        "\n",
        "RDDs are not executed until an action is performed and persist (store) its data in memory across the cluster for reuse.\n"
      ],
      "metadata": {
        "id": "kko2iBVFty4R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check # cores in our machine"
      ],
      "metadata": {
        "id": "DQ0MwLDct5wR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"Number of cores:\", os.cpu_count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXjSc-s_xSMZ",
        "outputId": "c0f7b250-3b11-4871-b10f-377e17f5896c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of cores: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "print(\"Number of cores:\", multiprocessing.cpu_count())"
      ],
      "metadata": {
        "id": "DfEmYBn3xesQ",
        "outputId": "999eb1d6-07cd-44eb-9170-d84173c36ba9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of cores: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### map function"
      ],
      "metadata": {
        "id": "5x3xjwvPvelC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext\n",
        "sc = SparkContext('local', 'hands on Pyspark')\n",
        "# Input RDD\n",
        "rdd = sc.parallelize([1, 2, 3, 4], numSlices=2)\n",
        "# Multiply each element by 2\n",
        "mapped_rdd = rdd.map(lambda x: x * 2)\n",
        "print(mapped_rdd.collect())  # Output: [2, 4, 6, 8]\n",
        "# sc.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aO0jceAmxjNv",
        "outputId": "9de37cbe-3f84-4a82-fc9a-0a1a1ba37558"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 4, 6, 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### check the number of partitions"
      ],
      "metadata": {
        "id": "Vr6aXBuTvnHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd.getNumPartitions() #2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-VoXC9GyK4A",
        "outputId": "fbd166d7-46c1-4355-bc19-23a4bded9b85"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### filter function"
      ],
      "metadata": {
        "id": "Ua9HHZ6hvubI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input RDD\n",
        "rdd = sc.parallelize([1, 2, 3, 4, 5, 6], numSlices = 3)\n",
        "# Keep only even numbers\n",
        "filtered_rdd = rdd.filter(lambda x: x % 2 == 0)\n",
        "print(filtered_rdd.collect())  # Output: [2, 4, 6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uLG-hZEyP3d",
        "outputId": "c4f760f2-ce2b-47e0-d376-ed8151e14810"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 4, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### reduce function"
      ],
      "metadata": {
        "id": "zdtRTBolv3Fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input RDD\n",
        "rdd = sc.parallelize([1, 2, 3, 4, 5], numSlices=2)\n",
        "# Sum all elements\n",
        "result = rdd.reduce(lambda x, y: x + y)\n",
        "print(result)  # Output: 15"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjEAsTrXyTuh",
        "outputId": "f1733d9f-8c52-4620-84ab-c45dc4756aba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inspect the contents in each partition\n"
      ],
      "metadata": {
        "id": "IDT4kW30v8Mo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an RDD with 2 partitions\n",
        "rdd = sc.parallelize([1, 2, 3, 4, 5, 6], numSlices=2)\n",
        "# Inspect contents of each partition\n",
        "partitions = rdd.glom().collect()\n",
        "# Print partition details\n",
        "for i, partition in enumerate(partitions):\n",
        "   print(f\"Partition {i}: {partition}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k57K4JwUyayj",
        "outputId": "e97275ab-ee5a-4b83-8c73-ac985ace18c1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Partition 0: [1, 2, 3]\n",
            "Partition 1: [4, 5, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Stop the SparkContext"
      ],
      "metadata": {
        "id": "SwXXHu2FwBpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc.stop()"
      ],
      "metadata": {
        "id": "Cn-Nsfx4ycny"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Partitions of a list of 10M integers"
      ],
      "metadata": {
        "id": "t1IP-1VuwMGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from pyspark import SparkContext\n",
        "\n",
        "# Initialize SparkContext\n",
        "sc = SparkContext(\"local\", \"Partition Example\")\n",
        "\n",
        "# Generate a list of 10,000,000 random integers in the range 1-1000\n",
        "data = [random.randint(1, 1000) for _ in range(10_000_000)]\n",
        "\n",
        "# Create an RDD without specifying the number of partitions (automatic partitioning)\n",
        "rdd = sc.parallelize(data)\n",
        "\n",
        "# Get the number of partitions\n",
        "num_partitions = rdd.getNumPartitions()\n",
        "print(f\"Number of partitions: {num_partitions}\") # ?\n",
        "\n",
        "# Inspect the data distribution in partitions\n",
        "partitions = rdd.glom().collect()  # glom groups data in each partition into lists\n",
        "\n",
        "# Print the first 5 elements of each partition (for illustration purposes)\n",
        "for i, partition in enumerate(partitions):\n",
        "    print(f\"Partition {i}: {partition[:5]}\")  # Print first 5 elements from each partition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvV56hQYypM_",
        "outputId": "a40fa127-18a1-471d-c76a-b56445d3baed"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of partitions: 1\n",
            "Partition 0: [55, 662, 741, 10, 135]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc.stop()"
      ],
      "metadata": {
        "id": "Xv-ryz05zTMz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Adjust number of partitions\n",
        "\n",
        "RDD size = Task Size x Number of Partitions\n",
        "\n",
        "Therefore, Number of Partitions = RDD Size/ Recommended Task Size"
      ],
      "metadata": {
        "id": "LPNUI7ffw0I5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from pyspark import SparkContext\n",
        "\n",
        "# Initialize SparkContext\n",
        "sc = SparkContext(\"local\", \"Partition Example\")\n",
        "\n",
        "# Create an RDD without specifying the number of partitions (automatic partitioning)\n",
        "rdd = sc.parallelize(data, numSlices = 28)\n",
        "\n",
        "# Get the number of partitions\n",
        "num_partitions = rdd.getNumPartitions()\n",
        "print(f\"Number of partitions: {num_partitions}\") # ?\n",
        "\n",
        "# Inspect the data distribution in partitions\n",
        "partitions = rdd.glom().collect()  # glom groups data in each partition into lists\n",
        "\n",
        "# Print the first 5 elements of each partition (for illustration purposes)\n",
        "for i, partition in enumerate(partitions):\n",
        "    print(f\"Partition {i}: {partition[:5]}\")  # Print first 5 elements from each partition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yjL3Cwr1KRP",
        "outputId": "25de0b35-6003-4bcc-bc4f-bf1a4bf8bb3d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of partitions: 28\n",
            "Partition 0: [55, 662, 741, 10, 135]\n",
            "Partition 1: [446, 214, 814, 566, 237]\n",
            "Partition 2: [169, 845, 564, 577, 551]\n",
            "Partition 3: [340, 435, 108, 263, 806]\n",
            "Partition 4: [664, 820, 318, 184, 32]\n",
            "Partition 5: [948, 544, 997, 835, 688]\n",
            "Partition 6: [673, 567, 920, 998, 185]\n",
            "Partition 7: [529, 984, 915, 160, 124]\n",
            "Partition 8: [512, 938, 720, 75, 828]\n",
            "Partition 9: [152, 469, 136, 5, 782]\n",
            "Partition 10: [759, 539, 221, 908, 742]\n",
            "Partition 11: [730, 698, 728, 881, 249]\n",
            "Partition 12: [749, 617, 526, 893, 951]\n",
            "Partition 13: [677, 670, 844, 771, 321]\n",
            "Partition 14: [25, 327, 116, 323, 674]\n",
            "Partition 15: [802, 111, 796, 272, 901]\n",
            "Partition 16: [208, 514, 102, 753, 869]\n",
            "Partition 17: [83, 49, 820, 482, 573]\n",
            "Partition 18: [977, 54, 400, 476, 756]\n",
            "Partition 19: [859, 523, 600, 214, 286]\n",
            "Partition 20: [828, 206, 303, 766, 635]\n",
            "Partition 21: [477, 237, 555, 199, 57]\n",
            "Partition 22: [262, 431, 664, 754, 842]\n",
            "Partition 23: [106, 304, 141, 274, 543]\n",
            "Partition 24: [193, 584, 580, 887, 617]\n",
            "Partition 25: [783, 929, 364, 454, 920]\n",
            "Partition 26: [469, 186, 867, 334, 1000]\n",
            "Partition 27: [399, 514, 654, 429, 729]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc.stop()"
      ],
      "metadata": {
        "id": "qcQ_IX6Y2Tuk"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}